{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /home/shashank/.pytorch/MNIST_data1/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9863168/9912422 [00:37<00:00, 576316.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/shashank/.pytorch/MNIST_data1/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /home/shashank/.pytorch/MNIST_data1/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\n",
      " 57%|█████▋    | 16384/28881 [00:01<00:00, 37297.53it/s]\u001b[A\n",
      "32768it [00:01, 28145.92it/s]                           \u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/shashank/.pytorch/MNIST_data1/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /home/shashank/.pytorch/MNIST_data1/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1648877 [00:01<?, ?it/s]\u001b[A\n",
      "  1%|          | 16384/1648877 [00:01<00:35, 46391.42it/s]\u001b[A\n",
      "  2%|▏         | 40960/1648877 [00:02<00:34, 46913.66it/s]\u001b[A\n",
      "  4%|▍         | 73728/1648877 [00:02<00:25, 62882.88it/s]\u001b[A\n",
      "  5%|▌         | 90112/1648877 [00:02<00:24, 63596.32it/s]\u001b[A\n",
      "  7%|▋         | 122880/1648877 [00:03<00:20, 73178.13it/s]\u001b[A\n",
      "  9%|▉         | 147456/1648877 [00:03<00:16, 91773.78it/s]\u001b[A\n",
      " 10%|█         | 172032/1648877 [00:03<00:18, 81259.26it/s]\u001b[A\n",
      " 12%|█▏        | 196608/1648877 [00:03<00:15, 93935.01it/s]\u001b[A\n",
      " 13%|█▎        | 212992/1648877 [00:03<00:16, 88683.87it/s]\u001b[A\n",
      " 14%|█▍        | 229376/1648877 [00:04<00:18, 78044.02it/s]\u001b[A\n",
      " 15%|█▍        | 245760/1648877 [00:04<00:19, 72143.17it/s]\u001b[A\n",
      " 16%|█▌        | 262144/1648877 [00:04<00:22, 61571.37it/s]\u001b[A\n",
      " 16%|█▋        | 270336/1648877 [00:04<00:20, 66183.02it/s]\u001b[A\n",
      " 17%|█▋        | 286720/1648877 [00:05<00:19, 68793.53it/s]\u001b[A\n",
      " 18%|█▊        | 294912/1648877 [00:05<00:29, 45259.77it/s]\u001b[A\n",
      " 19%|█▉        | 319488/1648877 [00:05<00:26, 50235.05it/s]\u001b[A\n",
      " 20%|█▉        | 327680/1648877 [00:05<00:23, 56498.65it/s]\u001b[A\n",
      " 20%|██        | 335872/1648877 [00:06<00:25, 52392.76it/s]\u001b[A\n",
      " 21%|██▏       | 352256/1648877 [00:06<00:19, 65161.61it/s]\u001b[A\n",
      " 23%|██▎       | 385024/1648877 [00:06<00:15, 83557.08it/s]\u001b[A\n",
      " 24%|██▍       | 401408/1648877 [00:06<00:17, 69890.95it/s]\u001b[A\n",
      " 25%|██▌       | 417792/1648877 [00:06<00:16, 75733.87it/s]\u001b[A\n",
      " 28%|██▊       | 466944/1648877 [00:07<00:11, 99919.35it/s]\u001b[A\n",
      " 30%|██▉       | 491520/1648877 [00:07<00:11, 99217.34it/s]\u001b[A\n",
      " 31%|███       | 507904/1648877 [00:07<00:11, 99804.94it/s]\u001b[A\n",
      " 32%|███▏      | 524288/1648877 [00:07<00:11, 100711.15it/s]\u001b[A\n",
      " 33%|███▎      | 548864/1648877 [00:07<00:09, 112580.95it/s]\u001b[A\n",
      " 34%|███▍      | 565248/1648877 [00:07<00:09, 114020.90it/s]\u001b[A\n",
      " 35%|███▌      | 581632/1648877 [00:08<00:09, 109197.92it/s]\u001b[A\n",
      " 36%|███▋      | 598016/1648877 [00:08<00:08, 121028.04it/s]\u001b[A\n",
      " 40%|████      | 663552/1648877 [00:08<00:06, 157629.74it/s]\u001b[A\n",
      " 43%|████▎     | 712704/1648877 [00:08<00:04, 194947.53it/s]\u001b[A\n",
      " 45%|████▌     | 745472/1648877 [00:08<00:04, 218529.58it/s]\u001b[A\n",
      " 48%|████▊     | 786432/1648877 [00:08<00:03, 253201.65it/s]\u001b[A\n",
      " 50%|█████     | 827392/1648877 [00:08<00:03, 225329.83it/s]\u001b[A\n",
      " 52%|█████▏    | 860160/1648877 [00:09<00:04, 185166.22it/s]\u001b[A\n",
      " 54%|█████▎    | 884736/1648877 [00:09<00:04, 163244.81it/s]\u001b[A\n",
      " 55%|█████▌    | 909312/1648877 [00:09<00:04, 173424.92it/s]\u001b[A\n",
      " 57%|█████▋    | 933888/1648877 [00:09<00:03, 179183.84it/s]\u001b[A\n",
      " 58%|█████▊    | 958464/1648877 [00:09<00:03, 188307.69it/s]\u001b[A\n",
      " 60%|█████▉    | 983040/1648877 [00:09<00:03, 193538.97it/s]\u001b[A\n",
      " 61%|██████    | 1007616/1648877 [00:09<00:03, 175661.61it/s]\u001b[A\n",
      " 63%|██████▎   | 1040384/1648877 [00:10<00:02, 203499.72it/s]\u001b[A\n",
      " 66%|██████▌   | 1089536/1648877 [00:10<00:02, 235817.22it/s]\u001b[A\n",
      " 68%|██████▊   | 1122304/1648877 [00:10<00:02, 243710.72it/s]\u001b[A\n",
      " 70%|███████   | 1155072/1648877 [00:10<00:01, 253183.43it/s]\u001b[A\n",
      " 72%|███████▏  | 1187840/1648877 [00:10<00:01, 266426.50it/s]\u001b[A\n",
      " 74%|███████▍  | 1220608/1648877 [00:10<00:01, 263834.80it/s]\u001b[A\n",
      " 76%|███████▌  | 1253376/1648877 [00:10<00:01, 265715.33it/s]\u001b[A\n",
      " 79%|███████▉  | 1302528/1648877 [00:10<00:01, 306142.98it/s]\u001b[A\n",
      " 81%|████████▏ | 1343488/1648877 [00:10<00:00, 319053.61it/s]\u001b[A\n",
      "9920512it [00:49, 576316.80it/s]                             \u001b[A\n",
      " 89%|████████▉ | 1466368/1648877 [00:11<00:00, 350195.63it/s]\u001b[A\n",
      " 92%|█████████▏| 1523712/1648877 [00:11<00:00, 385164.55it/s]\u001b[A\n",
      " 97%|█████████▋| 1605632/1648877 [00:11<00:00, 436366.22it/s]\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/shashank/.pytorch/MNIST_data1/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /home/shashank/.pytorch/MNIST_data1/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/4542 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "8192it [00:00, 10177.18it/s]            \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/shashank/.pytorch/MNIST_data1/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "### Run this cell\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data1/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n",
      "tensor(8)\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "print(labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x9pi/QgAZ83mwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1654784it [00:31, 436366.22it/s]                             \u001b[A"
     ]
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_output=10\n",
    "#flattening the images to get the input tensor of 784\n",
    "n_input=images.view(images.shape[0],-1)\n",
    "n_hidden=512\n",
    "def activation(x):\n",
    "    return (1/(1+torch.exp(-x)))\n",
    "\n",
    "#two layers\n",
    "W1=torch.randn(784,n_hidden)\n",
    "W2=torch.randn(n_hidden,n_output)\n",
    "#biases\n",
    "B1=torch.randn((1,n_hidden))\n",
    "B2=torch.randn((1,n_output))\n",
    "\n",
    "h=activation(torch.matmul(n_input,W1)+B1)\n",
    "\n",
    "out =torch.matmul(h,W2)+B2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.6573e-01, 3.8830e-15, 1.7915e-06, 3.4263e-02, 1.1771e-13, 1.2916e-11,\n",
      "         4.6748e-16, 9.8402e-10, 1.1213e-12, 2.7307e-06],\n",
      "        [4.4739e-06, 5.0284e-13, 2.4063e-15, 5.2738e-01, 7.9959e-03, 1.3148e-18,\n",
      "         1.0936e-19, 3.8589e-23, 1.6301e-11, 4.6461e-01],\n",
      "        [5.1852e-09, 7.8379e-13, 1.5425e-02, 9.8137e-01, 1.0840e-08, 2.8543e-11,\n",
      "         6.1296e-13, 6.3912e-16, 1.4742e-04, 3.0569e-03],\n",
      "        [8.7156e-01, 6.4048e-13, 7.8945e-03, 7.3593e-02, 4.6948e-02, 1.0727e-18,\n",
      "         1.6296e-21, 1.0053e-15, 1.6325e-11, 2.2698e-12],\n",
      "        [1.8030e-10, 7.6433e-14, 5.6194e-12, 9.7437e-01, 2.5628e-02, 1.2546e-11,\n",
      "         1.4129e-16, 7.9981e-14, 9.2726e-09, 3.6577e-13],\n",
      "        [9.2130e-17, 2.5441e-09, 6.9583e-13, 1.0000e+00, 5.8216e-08, 3.4204e-15,\n",
      "         6.1043e-18, 2.0505e-16, 7.3876e-11, 1.4578e-14],\n",
      "        [2.6231e-14, 1.1429e-09, 9.1535e-17, 8.0283e-01, 5.1331e-13, 1.9909e-12,\n",
      "         1.7272e-16, 3.6020e-15, 5.0146e-08, 1.9717e-01],\n",
      "        [6.2097e-05, 1.2790e-20, 1.1143e-10, 9.9994e-01, 3.1916e-12, 1.3861e-13,\n",
      "         1.4868e-20, 3.5903e-19, 1.6354e-10, 7.8989e-13],\n",
      "        [3.4525e-09, 3.6039e-13, 1.3541e-11, 1.0000e+00, 1.1763e-10, 5.3868e-14,\n",
      "         4.2883e-18, 4.7706e-21, 5.6871e-09, 3.0221e-07],\n",
      "        [9.7057e-01, 9.1840e-10, 4.8980e-07, 5.1611e-03, 9.0130e-08, 3.0096e-07,\n",
      "         5.2629e-09, 6.8870e-09, 2.4268e-02, 6.8943e-13],\n",
      "        [9.9999e-01, 7.7230e-15, 3.9282e-09, 1.6918e-07, 2.5945e-06, 1.2751e-13,\n",
      "         1.9610e-16, 2.0733e-18, 7.7029e-18, 5.2885e-06],\n",
      "        [9.3501e-01, 7.7983e-11, 7.0080e-09, 6.4980e-02, 1.0240e-10, 4.0418e-14,\n",
      "         1.4652e-16, 6.4625e-18, 1.6862e-13, 1.2658e-05],\n",
      "        [2.4916e-06, 2.5334e-16, 1.8745e-15, 1.0000e+00, 4.9627e-14, 1.2362e-13,\n",
      "         2.9311e-18, 1.6033e-18, 1.4503e-07, 3.2715e-15],\n",
      "        [1.5895e-04, 7.1706e-08, 5.5351e-12, 9.9978e-01, 3.4662e-05, 7.1198e-07,\n",
      "         8.9560e-11, 6.2221e-15, 1.1747e-09, 2.1369e-05],\n",
      "        [7.1148e-03, 6.7340e-17, 1.4335e-12, 9.9289e-01, 1.6687e-11, 1.1951e-10,\n",
      "         6.2100e-16, 3.7242e-20, 5.7027e-09, 1.4984e-13],\n",
      "        [5.2603e-06, 4.5417e-12, 7.0145e-07, 9.9680e-01, 1.2697e-05, 4.5797e-15,\n",
      "         6.8890e-23, 6.3313e-16, 8.6736e-10, 3.1846e-03],\n",
      "        [9.8693e-01, 1.0246e-13, 3.7468e-03, 8.5337e-03, 7.6555e-12, 3.6278e-07,\n",
      "         5.3236e-14, 2.4591e-09, 1.2545e-08, 7.8765e-04],\n",
      "        [5.9157e-08, 6.0702e-11, 2.7842e-07, 1.5714e-01, 2.1192e-08, 2.9601e-10,\n",
      "         6.9219e-19, 4.8512e-25, 8.9078e-11, 8.4285e-01],\n",
      "        [3.0191e-11, 4.0130e-11, 3.8928e-09, 1.0000e+00, 1.8689e-07, 2.1616e-14,\n",
      "         1.1844e-13, 2.8863e-18, 4.7507e-08, 2.8257e-15],\n",
      "        [4.0543e-04, 6.6195e-12, 2.8359e-06, 1.6139e-04, 1.4237e-08, 1.0820e-07,\n",
      "         8.9227e-16, 1.4254e-16, 9.9941e-01, 1.7616e-05],\n",
      "        [6.2731e-07, 8.3011e-11, 9.1878e-10, 9.8191e-01, 1.3768e-06, 4.3830e-05,\n",
      "         1.4387e-12, 1.1741e-12, 1.8048e-02, 4.2815e-07],\n",
      "        [1.7975e-14, 1.2488e-10, 5.9944e-09, 9.9998e-01, 4.5870e-07, 1.0524e-11,\n",
      "         1.0296e-13, 3.8001e-15, 1.7958e-05, 1.3019e-09],\n",
      "        [6.4968e-04, 7.3622e-07, 2.5359e-05, 9.9647e-01, 1.9726e-06, 4.2082e-07,\n",
      "         8.3862e-08, 1.9397e-18, 3.5024e-04, 2.5050e-03],\n",
      "        [3.6718e-01, 2.7776e-05, 1.0858e-08, 6.3277e-01, 3.5263e-06, 3.3428e-08,\n",
      "         1.7598e-12, 3.5966e-16, 1.5008e-05, 6.9337e-07],\n",
      "        [8.4649e-09, 1.2635e-14, 2.3401e-11, 1.0000e+00, 3.4987e-15, 3.2001e-14,\n",
      "         1.4498e-20, 7.6711e-21, 2.7114e-11, 6.4271e-11],\n",
      "        [4.3427e-04, 2.2726e-03, 9.1019e-07, 2.4628e-01, 1.0123e-08, 2.8365e-11,\n",
      "         3.3449e-13, 6.2566e-20, 1.5386e-06, 7.5101e-01],\n",
      "        [5.1493e-08, 5.6566e-11, 6.7718e-09, 9.9988e-01, 1.1887e-04, 1.9228e-06,\n",
      "         4.0074e-12, 9.2284e-08, 1.7099e-10, 2.7183e-07],\n",
      "        [5.9762e-11, 1.2453e-07, 2.8604e-15, 1.0000e+00, 2.5837e-13, 4.2784e-14,\n",
      "         8.7137e-19, 1.8979e-16, 9.9112e-09, 3.1408e-09],\n",
      "        [4.3131e-07, 4.6477e-14, 3.5771e-08, 9.9717e-01, 2.1638e-04, 1.7578e-07,\n",
      "         7.1263e-15, 6.1268e-17, 1.5337e-08, 2.6159e-03],\n",
      "        [5.0982e-05, 7.3955e-07, 1.6770e-05, 9.9732e-01, 2.2372e-07, 8.1197e-05,\n",
      "         5.3454e-13, 2.1225e-10, 5.7183e-07, 2.5298e-03],\n",
      "        [6.6730e-05, 6.3335e-04, 2.7412e-01, 4.6820e-01, 2.4211e-01, 8.8130e-08,\n",
      "         2.2224e-10, 2.3910e-13, 9.8151e-09, 1.4869e-02],\n",
      "        [6.5350e-08, 9.5024e-13, 5.4081e-07, 9.9977e-01, 1.8223e-13, 9.7324e-15,\n",
      "         3.7419e-15, 3.0853e-16, 1.1483e-08, 2.2536e-04],\n",
      "        [1.4238e-06, 9.5187e-04, 1.1135e-07, 9.2941e-01, 9.2440e-12, 3.2890e-11,\n",
      "         2.9446e-14, 9.2267e-21, 6.9479e-02, 1.5792e-04],\n",
      "        [4.4114e-04, 4.0507e-12, 3.6805e-03, 1.5327e-03, 1.2793e-08, 1.5964e-10,\n",
      "         5.3360e-15, 1.9893e-18, 7.5835e-07, 9.9434e-01],\n",
      "        [4.6371e-09, 8.9799e-07, 3.5919e-07, 1.0000e+00, 3.0406e-08, 2.8939e-16,\n",
      "         9.3326e-19, 3.0258e-16, 1.2116e-07, 2.0658e-12],\n",
      "        [1.4167e-04, 2.0283e-11, 7.7817e-01, 2.1977e-01, 1.5671e-05, 3.6780e-04,\n",
      "         2.5053e-11, 4.7676e-14, 1.5265e-03, 6.6654e-08],\n",
      "        [5.1237e-06, 2.1250e-11, 1.2246e-05, 9.9993e-01, 5.9509e-08, 5.4864e-05,\n",
      "         5.5577e-11, 2.0050e-13, 1.9033e-06, 3.0097e-11],\n",
      "        [1.7532e-05, 1.2676e-16, 2.5846e-07, 9.9975e-01, 2.3238e-04, 1.2542e-17,\n",
      "         3.3740e-17, 1.2588e-17, 2.2584e-13, 2.7594e-10],\n",
      "        [6.5771e-03, 1.9867e-08, 3.2650e-13, 9.9340e-01, 3.8045e-12, 1.3433e-07,\n",
      "         4.7892e-13, 1.0195e-16, 4.8746e-10, 2.5813e-05],\n",
      "        [2.2464e-10, 2.6855e-11, 2.2357e-17, 1.0000e+00, 8.7658e-16, 4.0002e-11,\n",
      "         1.1087e-15, 5.1092e-19, 3.8230e-15, 1.4316e-07],\n",
      "        [1.7446e-05, 1.0437e-08, 2.4294e-06, 9.8996e-01, 6.0291e-03, 3.2466e-04,\n",
      "         1.2328e-13, 2.1948e-12, 3.6693e-03, 1.6768e-07],\n",
      "        [5.9558e-08, 8.3243e-10, 1.1603e-11, 1.0000e+00, 4.7172e-13, 3.2122e-16,\n",
      "         1.4472e-13, 2.6116e-24, 3.4782e-12, 1.4844e-08],\n",
      "        [9.7525e-13, 3.6891e-14, 3.0858e-11, 1.0000e+00, 1.5227e-19, 1.6110e-17,\n",
      "         7.0835e-19, 1.1344e-20, 3.1750e-08, 4.8256e-06],\n",
      "        [2.0904e-05, 1.2649e-18, 1.2703e-09, 9.9996e-01, 1.6877e-08, 1.7479e-08,\n",
      "         5.7956e-12, 2.6179e-11, 2.1478e-05, 1.2330e-14],\n",
      "        [3.7357e-04, 1.2360e-06, 4.7967e-17, 9.9950e-01, 6.9744e-09, 4.4915e-12,\n",
      "         6.8663e-09, 7.0901e-12, 1.1041e-04, 1.6525e-05],\n",
      "        [1.5022e-10, 1.4601e-18, 1.0033e-10, 1.0000e+00, 1.8365e-18, 1.0806e-17,\n",
      "         6.8536e-20, 1.0311e-24, 1.5571e-15, 3.9799e-08],\n",
      "        [8.8592e-05, 3.6255e-10, 2.6307e-05, 1.3849e-01, 8.6091e-01, 6.3468e-10,\n",
      "         6.7890e-13, 6.0885e-08, 4.8011e-04, 6.9645e-07],\n",
      "        [5.5460e-10, 7.4017e-13, 1.9369e-09, 7.2838e-01, 2.0935e-01, 3.1363e-08,\n",
      "         2.9159e-14, 1.9960e-13, 2.6396e-07, 6.2267e-02],\n",
      "        [1.0026e-08, 1.4461e-12, 3.2222e-11, 1.0000e+00, 5.4580e-13, 9.5306e-14,\n",
      "         2.1171e-18, 6.8726e-19, 2.6730e-10, 1.3201e-06],\n",
      "        [1.1230e-10, 3.9939e-16, 3.7917e-19, 1.0000e+00, 3.3831e-19, 5.1212e-18,\n",
      "         5.5816e-19, 1.0524e-19, 4.5426e-13, 1.2996e-15],\n",
      "        [9.9987e-01, 9.4435e-16, 1.2897e-10, 1.2615e-04, 1.7716e-07, 5.2376e-13,\n",
      "         3.6957e-15, 1.3756e-14, 4.5130e-11, 8.0360e-12],\n",
      "        [2.0477e-06, 3.1651e-07, 3.2261e-04, 6.7772e-01, 2.9989e-07, 3.2275e-09,\n",
      "         4.9096e-10, 1.8993e-15, 1.1949e-01, 2.0247e-01],\n",
      "        [4.7967e-09, 2.0521e-14, 2.0675e-05, 9.9998e-01, 5.3132e-11, 4.4343e-15,\n",
      "         1.2119e-18, 2.0257e-20, 3.8932e-12, 2.2083e-08],\n",
      "        [9.5298e-15, 1.4718e-10, 8.6670e-14, 9.7827e-01, 7.5958e-07, 3.7871e-17,\n",
      "         2.2587e-14, 3.1860e-20, 2.1725e-02, 1.1725e-07],\n",
      "        [6.8429e-01, 3.7750e-04, 5.6793e-04, 3.1433e-01, 1.4028e-07, 2.4933e-10,\n",
      "         6.2028e-15, 5.1997e-16, 1.4940e-06, 4.4035e-04],\n",
      "        [7.9353e-09, 1.1172e-15, 4.4445e-11, 9.7930e-01, 9.4637e-09, 2.8889e-12,\n",
      "         1.4318e-18, 4.1062e-19, 1.5156e-08, 2.0696e-02],\n",
      "        [2.9407e-07, 1.1139e-07, 2.1969e-05, 9.4128e-01, 5.8688e-02, 1.1707e-12,\n",
      "         3.1371e-09, 3.4883e-14, 5.8156e-06, 1.1497e-08],\n",
      "        [5.1770e-01, 3.9572e-11, 2.1053e-06, 4.8229e-01, 1.2270e-07, 6.5819e-14,\n",
      "         1.5730e-09, 3.6324e-12, 1.2239e-05, 1.4250e-10],\n",
      "        [1.2281e-03, 2.1557e-09, 3.4607e-10, 9.9786e-01, 8.2590e-13, 2.6529e-04,\n",
      "         4.8332e-11, 7.5131e-17, 6.4833e-04, 1.2844e-10],\n",
      "        [5.3955e-19, 5.6536e-14, 1.4475e-12, 1.0000e+00, 9.1021e-08, 3.4102e-18,\n",
      "         3.9362e-19, 2.0587e-26, 5.8300e-13, 1.5556e-08],\n",
      "        [9.9706e-01, 8.6017e-10, 5.0837e-10, 2.9421e-03, 2.2377e-09, 1.7244e-08,\n",
      "         4.3571e-16, 1.0022e-10, 3.8662e-09, 4.9199e-08],\n",
      "        [5.4659e-05, 5.9532e-11, 2.9379e-11, 9.9992e-01, 2.4871e-05, 9.8021e-17,\n",
      "         1.4715e-13, 2.4804e-16, 3.8437e-09, 1.7475e-07],\n",
      "        [1.7369e-06, 1.0408e-13, 9.0283e-11, 1.0000e+00, 4.1794e-12, 6.7852e-14,\n",
      "         1.1350e-17, 1.8927e-16, 8.3706e-09, 1.1932e-08],\n",
      "        [1.1825e-03, 4.5169e-10, 1.8450e-12, 9.7727e-01, 5.3857e-07, 4.2149e-07,\n",
      "         2.8748e-11, 7.7015e-16, 2.1545e-02, 7.7960e-08]])\n",
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "#To find out the probability between 0 & 1 and sum upto 1\n",
    "def softmax(x):\n",
    "    ## TODO: Implement the softmax function here\n",
    "    return torch.exp(x)/(torch.sum(torch.exp(x),dim=1)).view(-1,1)\n",
    "\n",
    "# Here, out should be the output of the network in the previous excercise with shape (64,10)\n",
    "probabilities = softmax(out)\n",
    "print(probabilities)\n",
    "# Does it have the right shape? Should be (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Does it sum to 1?\n",
    "print(probabilities.sum(dim=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Networks with Pytorch using nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden1 = nn.Linear(784, 256)\n",
    "        self.hidden2=nn.Linear(256,64)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        \n",
    "        self.output = nn.Linear(64, 10)\n",
    "        \n",
    "        # Define sigmoid activation and softmax output \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (hidden2): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the network and look at it's text representation\n",
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or can be done using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (hidden2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your solution here\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.input=nn.Linear(784,512)\n",
    "        self.hidden1=nn.Linear(784,128)\n",
    "        self.hidden2=nn.Linear(128,64)\n",
    "        self.output=nn.Linear(64,10)\n",
    "        #self.loss_layer=nn.CrossEntropyLoss()\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.hidden1(x))\n",
    "        x=F.relu(self.hidden2(x))\n",
    "        x=F.softmax(self.output(x))\n",
    "        #x=F.cross_entropy()\n",
    "        return x\n",
    "model=Network()\n",
    "model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
